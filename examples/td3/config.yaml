# Environment
env_name: HalfCheetah-v4
env_task: ""
env_library: gym
record_video: 0
normalize_rewards_online: 0
normalize_rewards_online_scale: 5
normalize_rewards_online_decay: 0.99
total_frames: 1000000
frames_per_batch: 1024
max_frames_per_traj: -1
frame_skip: 1
from_pixels: 0
# Collection
init_random_frames: 5000
init_env_steps: 10000
record_interval: 10
record_frames: 10000
async_collection: 1
#collector_devices: [cuda:1,cuda:1,cuda:1,cuda:1]
collector_devices: [cpu] # ,cpu,cpu,cpu]
env_per_collector: 1
num_workers: 1
# Optimization
loss: double
loss_function: smooth_l1
lr: 3e-4
weight_decay: 0.0
lr_scheduler: ""
optim_steps_per_batch: 128
batch_size: 256
value_network_update_interval: 200
# Algorithm
prb: 0 # use prioritized experience replay
policy_update_delay: 2
multi_step: 0
n_steps_return: 1
activation: relu
gSDE: 0

# Logging
logger: wandb

# Extra
batch_transform: 1
buffer_prefetch: 64
norm_stats: 1