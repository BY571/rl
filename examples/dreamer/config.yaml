env:
  name: cheetah
  task: run
  seed: 0
  backend: dm_control
  catframes: 1
  record_video: 0
  frame_skip: 2
  from_pixels: True
  grayscale: False
  image_size : 64
  center_crop: False
  batch_transform: 1

  # # probably not needed vvvv
  # normalize_rewards_online: True
  # normalize_rewards_online_scale: 5.0
  # normalize_rewards_online_decay: 0.99999
  # reward_scaling: 1.0

collector:
  total_frames: 5_000_000
  init_env_steps: 1000
  init_random_frames: 1000
  frames_per_batch: 1000
  max_frames_per_traj: 1000
  device: cpu


optimization:
  train_every: 1000
  train_steps: 100
  pretrain: 100
  grad_clip: 100
  batch_size: 50
  batch_length: 50

  world_model_lr: 6e-4
  actor_lr: 8e-5
  value_lr: 8e-5
  kl_scale: 1.0
  free_nats: 3.0
  optim_steps_per_batch: 80
  gamma: 0.99
  lambda: 0.95
  imagination_horizon: 15


# we want 50 frames / traj in the replay buffer. Given the frame_skip=2 this makes each traj 100 steps long
networks:
  # additive gaussian exploration
  exploration_noise: 0.3
  device: cuda:0
  state_dim: 30
  rssm_hidden_dim: 200
  hidden_dim: 400
  activation: "elu"


replay_buffer: 
  uint8_casting: True
  buffer_size: 20000
  batch_size: 50
  scratch_dir: ${logger.exp_name}_${env.seed}



logger:
  backend: wandb
  project: dreamer-v1
  exp_name: ${env.name}-${env.task}-${env.seed}
  mode: online
  record_interval: 30
  record_frames: 1000
  eval_iter: 1000
  eval_rollout_steps: 1000
